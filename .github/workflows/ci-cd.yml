name: .NET CI/CD Pipeline

on:
  push:
    branches: [ main, lab_test_1 ]
  pull_request:
    branches: [ main, lab_test_1 ]

jobs:
  unit-tests:
    name: Run Unit Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup .NET 7.0
      uses: actions/setup-dotnet@v3
      with:
        dotnet-version: '7.0.x'
        
    - name: Find solution and project files
      run: |
        echo "Solution files:"
        find . -name "*.sln"
        echo "Project files:"
        find . -name "*.csproj"
        echo "Test project files:"
        find . -name "*Tests*.csproj"
      
    - name: Restore dependencies
      run: dotnet restore
      working-directory: ./FlowerShop
      
    - name: Build solution
      run: dotnet build --no-restore --configuration Release
      working-directory: ./FlowerShop
      
    - name: Run unit tests
      run: |
        dotnet test --filter Category=Unit --configuration Release --no-build --verbosity normal \
        --logger "trx;LogFileName=unit-test-results.trx" \
        --results-directory TestResults/Unit
      working-directory: ./FlowerShop
      continue-on-error: false
      
    - name: Upload unit test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: unit-test-results
        path: FlowerShop/TestResults/Unit/
        retention-days: 30

  integration-tests:
    name: Run Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    if: needs.unit-tests.result == 'success'
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: 5432
          POSTGRES_DB: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup .NET 7.0
      uses: actions/setup-dotnet@v3
      with:
        dotnet-version: '7.0.x'
        
    - name: Install PostgreSQL client
      run: |
        sudo apt-get update
        sudo apt-get install -y postgresql-client
        
    - name: Wait for PostgreSQL
      run: |
        for i in {1..30}; do
          if pg_isready -h localhost -p 5432 -U postgres; then
            echo "PostgreSQL is ready"
            break
          fi
          echo "Waiting for PostgreSQL... ($i/30)"
          sleep 2
        done
        
    - name: Initialize test database
      run: |
        PGPASSWORD=5432 psql -h localhost -U postgres -d postgres -c "CREATE DATABASE flowershoptest;"
        
    - name: Restore dependencies
      run: dotnet restore
      working-directory: ./FlowerShop
      
    - name: Build solution
      run: dotnet build --no-restore --configuration Release
      working-directory: ./FlowerShop
      
    - name: Run integration tests
      env:
        TEST_CONNECTION_STRING: "Host=localhost;Port=5432;Database=flowershoptest;Username=postgres;Password=5432;Include Error Detail=true"
      run: |
        dotnet test --filter Category=Integration --configuration Release --no-build --verbosity normal \
        --logger "trx;LogFileName=integration-test-results.trx" \
        --results-directory TestResults/Integration
      working-directory: ./FlowerShop
      continue-on-error: false
      
    - name: Upload integration test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: FlowerShop/TestResults/Integration/
        retention-days: 30
        
    - name: Cleanup test database
      if: always()
      run: |
        # Завершаем все активные соединения с тестовой БД
        PGPASSWORD=5432 psql -h localhost -U postgres -d postgres -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'flowershoptest' AND pid <> pg_backend_pid();"
        
        # Небольшая задержка для завершения процессов
        sleep 2
        
        # Удаляем тестовую БД
        PGPASSWORD=5432 psql -h localhost -U postgres -d postgres -c "DROP DATABASE IF EXISTS flowershoptest;"
        
        echo "Test database cleanup completed"

  e2e-tests:
    name: Run E2E Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    if: needs.integration-tests.result == 'success'
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: 5432
          POSTGRES_DB: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup .NET 7.0
      uses: actions/setup-dotnet@v3
      with:
        dotnet-version: '7.0.x'
        
    - name: Install PostgreSQL client
      run: |
        sudo apt-get update
        sudo apt-get install -y postgresql-client
        
    - name: Wait for PostgreSQL
      run: |
        for i in {1..30}; do
          if pg_isready -h localhost -p 5432 -U postgres; then
            echo "PostgreSQL is ready"
            break
          fi
          echo "Waiting for PostgreSQL... ($i/30)"
          sleep 2
        done
        
    - name: Initialize test database
      run: |
        PGPASSWORD=5432 psql -h localhost -U postgres -d postgres -c "CREATE DATABASE flowershoptest;"
        
    - name: Restore dependencies
      run: dotnet restore
      working-directory: ./FlowerShop
      
    - name: Build solution
      run: dotnet build --no-restore --configuration Release
      working-directory: ./FlowerShop
      
    - name: Run E2E tests
      env:
        TEST_CONNECTION_STRING: "Host=localhost;Port=5432;Database=flowershoptest;Username=postgres;Password=5432;Include Error Detail=true"
      run: |
        dotnet test --filter Category=E2E --configuration Release --no-build --verbosity normal \
        --logger "trx;LogFileName=e2e-test-results.trx" \
        --results-directory TestResults/E2E
      working-directory: ./FlowerShop
      continue-on-error: false
      
    - name: Upload E2E test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: e2e-test-results
        path: FlowerShop/TestResults/E2E/
        retention-days: 30
        
    - name: Cleanup test database
      if: always()
      run: |
        # Завершаем все активные соединения с тестовой БД
        PGPASSWORD=5432 psql -h localhost -U postgres -d postgres -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'flowershoptest' AND pid <> pg_backend_pid();"
        
        # Небольшая задержка для завершения процессов
        sleep 2
        
        # Удаляем тестовую БД
        PGPASSWORD=5432 psql -h localhost -U postgres -d postgres -c "DROP DATABASE IF EXISTS flowershoptest;"
        
        echo "Test database cleanup completed"

  test-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs: 
      - unit-tests
      - integration-tests  
      - e2e-tests
    if: always()
    
    # Разрешаем запись на Check API только для внутренних PR
    permissions:
      checks: write
      actions: read
      contents: read
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Download all test results
      uses: actions/download-artifact@v4
      with:
        path: artifacts
        
    - name: Create valid skipped test result files
      run: |
        # Создаем корректные TRX файлы для пропущенных тестов с минимальным набором тестов
        mkdir -p artifacts/skipped
        
        # Создаем директории для каждого типа тестов
        mkdir -p artifacts/unit-test-results
        mkdir -p artifacts/integration-test-results  
        mkdir -p artifacts/e2e-test-results
        
        # Функция для создания валидного TRX файла с одним пропущенным тестом
        create_skipped_trx() {
          local test_type=$1
          local filename=$2
          local run_id=$(uuidgen)
          local creation_time=$(date -u +"%Y-%m-%dT%H:%M:%S.0000000Z")
          local finish_time=$(date -u +"%Y-%m-%dT%H:%M:%S.0000000Z")
          
          cat > "$filename" << EOF
        <?xml version="1.0" encoding="utf-8"?>
        <TestRun id="$run_id" name="$test_type Tests" runUser="GitHub Actions" xmlns="http://microsoft.com/schemas/VisualStudio/TeamTest/2010">
          <Times creation="$creation_time" finish="$finish_time"/>
          <ResultSummary outcome="NotExecuted">
            <Counters total="1" executed="0" passed="0" failed="0" error="0" timeout="0" aborted="0" inconclusive="0" passedButRunAborted="0" notRunnable="0" notExecuted="1" disconnected="0" warning="0" completed="0" inProgress="0" pending="0"/>
            <Output>
              <StdOut>Test suite was skipped due to previous job failure: $test_type Tests</StdOut>
            </Output>
          </ResultSummary>
          <TestDefinitions>
            <UnitTest name="Skipped_${test_type}_Test" storage="dummy.dll" id="$(uuidgen)">
              <Execution id="$(uuidgen)"/>
              <TestMethod codeBase="dummy.dll" className="SkippedTests" name="Skipped_${test_type}_Test"/>
            </UnitTest>
          </TestDefinitions>
          <TestLists>
            <TestList name="Results Not in a List" id="8c84fa94-04c1-424b-9868-57a2d4851a1d"/>
            <TestList name="All Loaded Results" id="19431567-8539-422a-85d7-44ee4e166bda"/>
          </TestLists>
          <TestEntries>
            <TestEntry testId="$(uuidgen)" executionId="$(uuidgen)" testListId="19431567-8539-422a-85d7-44ee4e166bda"/>
          </TestEntries>
          <Results>
            <UnitTestResult testName="Skipped_${test_type}_Test" outcome="NotExecuted" testListId="19431567-8539-422a-85d7-44ee4e166bda">
              <Output>
                <StdOut>Test was skipped because the $test_type test job did not run due to previous stage failure.</StdOut>
              </Output>
            </UnitTestResult>
          </Results>
        </TestRun>
        EOF
        }
        
        # Создаем пропущенные файлы для jobs, которые не выполнились
        if [[ "${{ needs.integration-tests.result }}" != "success" ]]; then
          create_skipped_trx "Integration" "artifacts/integration-test-results/integration-test-results.trx"
          echo "Created valid skipped result for integration tests"
        fi
        
        if [[ "${{ needs.e2e-tests.result }}" != "success" ]]; then
          create_skipped_trx "E2E" "artifacts/e2e-test-results/e2e-test-results.trx"
          echo "Created valid skipped result for E2E tests"
        fi
        
        echo "Valid skipped test result files created successfully"
      
    - name: List downloaded artifacts
      run: |
        echo "=== Artifacts structure ==="
        find artifacts -name "*.trx" -type f | head -20
        echo "=== Total TRX files found: ==="
        find artifacts -name "*.trx" -type f | wc -l

    - name: Publish Test Results for Internal PR
      if: github.event.pull_request.head.repo.full_name == github.repository || github.event_name != 'pull_request'
      uses: dorny/test-reporter@v1
      with:
        name: Test Results
        path: artifacts/**/*.trx
        reporter: dotnet-trx
        fail-on-error: false
        
    - name: Skip Test Results for Fork PR
      if: github.event.pull_request.head.repo.full_name != github.repository && github.event_name == 'pull_request'
      run: |
        echo "Skipping test report publication for fork PR due to security restrictions"
        echo "Test artifacts are available for download in the workflow run"
        echo "Unit Tests: ${{ needs.unit-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}" 
        echo "E2E Tests: ${{ needs.e2e-tests.result }}"
        
    - name: Generate Detailed Test Summary
      if: always()
      run: |
        echo "## Comprehensive Test Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo "### Job Execution Status" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Test Stage | Status | Details |" >> $GITHUB_STEP_SUMMARY
        echo "|------------|--------|---------|" >> $GITHUB_STEP_SUMMARY
        
        # Unit Tests
        if [[ "${{ needs.unit-tests.result }}" == "success" ]]; then
          echo "| Unit Tests | Success | All unit tests passed |" >> $GITHUB_STEP_SUMMARY
        elif [[ "${{ needs.unit-tests.result }}" == "failure" ]]; then
          echo "| Unit Tests | Failed | Check unit test results for details |" >> $GITHUB_STEP_SUMMARY
        else
          echo "| Unit Tests | Unknown | Unexpected status |" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Integration Tests
        if [[ "${{ needs.integration-tests.result }}" == "success" ]]; then
          echo "| Integration Tests | Success | All integration tests passed |" >> $GITHUB_STEP_SUMMARY
        elif [[ "${{ needs.integration-tests.result }}" == "failure" ]]; then
          echo "| Integration Tests | Failed | Check integration test results for details |" >> $GITHUB_STEP_SUMMARY
        elif [[ "${{ needs.integration-tests.result }}" == "skipped" ]]; then
          echo "| Integration Tests | Skipped | Previous job failed, tests were not executed |" >> $GITHUB_STEP_SUMMARY
        else
          echo "| Integration Tests | Unknown | Unexpected status |" >> $GITHUB_STEP_SUMMARY
        fi
        
        # E2E Tests
        if [[ "${{ needs.e2e-tests.result }}" == "success" ]]; then
          echo "| E2E Tests | Success | All end-to-end tests passed |" >> $GITHUB_STEP_SUMMARY
        elif [[ "${{ needs.e2e-tests.result }}" == "failure" ]]; then
          echo "| E2E Tests | Failed | Check E2E test results for details |" >> $GITHUB_STEP_SUMMARY
        elif [[ "${{ needs.e2e-tests.result }}" == "skipped" ]]; then
          echo "| E2E Tests | Skipped | Previous job failed, tests were not executed |" >> $GITHUB_STEP_SUMMARY
        else
          echo "| E2E Tests | Unknown | Unexpected status |" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Pipeline Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Добавляем информацию о доступности отчета
        if [[ "${{ github.event.pull_request.head.repo.full_name != github.repository && github.event_name == 'pull_request' }}" == "true" ]]; then
          echo "> **Security Notice**: Detailed test reports are limited for pull requests from forks." >> $GITHUB_STEP_SUMMARY
          echo "> Test artifacts are available for download in the workflow run." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [[ "${{ needs.unit-tests.result }}" == "success" && "${{ needs.integration-tests.result }}" == "success" && "${{ needs.e2e-tests.result }}" == "success" ]]; then
          echo "**All tests passed successfully!** The application is ready for deployment." >> $GITHUB_STEP_SUMMARY
        else
          echo "**Some tests failed or were skipped.** Please review the test results above." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Next steps:**" >> $GITHUB_STEP_SUMMARY
          echo "1. Check the detailed test reports in the artifacts" >> $GITHUB_STEP_SUMMARY
          echo "2. Review failed tests and fix the issues" >> $GITHUB_STEP_SUMMARY
          echo "3. Re-run the pipeline after fixes" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "*Report generated automatically by GitHub Actions*" >> $GITHUB_STEP_SUMMARY